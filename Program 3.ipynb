{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7554e0",
   "metadata": {},
   "source": [
    "# Program 3 - Classification using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d3810",
   "metadata": {},
   "source": [
    "George Bennett, Spring 2022 - CS CS461"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a91bdb",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b7ffd",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9132d",
   "metadata": {},
   "source": [
    "First we use pandas to manipulate and clean up data from the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe61ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b0d99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592803 entries, 0 to 592802\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   favorite_count  592803 non-null  int64  \n",
      " 1   full_text       592803 non-null  object \n",
      " 2   hashtags        592803 non-null  object \n",
      " 3   retweet_count   592803 non-null  int64  \n",
      " 4   year            574091 non-null  float64\n",
      " 5   party_id        592803 non-null  object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 27.1+ MB\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(\"congressional_tweet_training_data.csv\", encoding = 'utf8')\n",
    "csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd107b1a",
   "metadata": {},
   "source": [
    "Here we are going to process the data so it's a little more friendlier for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700897b",
   "metadata": {},
   "source": [
    "We take the CSV of Tweets and I converting the data types of each column to the appropriate ones which match the type of data for the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce8756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = csv.copy()\n",
    "\n",
    "dataset[\"full_text\"] = dataset[\"full_text\"].astype(\"string\")\n",
    "dataset[\"party_id\"] = dataset[\"party_id\"].astype(\"category\")\n",
    "dataset[\"hashtags\"] = dataset[\"hashtags\"].astype(\"string\")\n",
    "dataset[\"year\"] = dataset[\"year\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520b2e3",
   "metadata": {},
   "source": [
    "A preview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5cb28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592798</th>\n",
       "      <td>3</td>\n",
       "      <td>b'This time, it focused on careers in #publics...</td>\n",
       "      <td>publicservice publicsafety</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592799</th>\n",
       "      <td>5</td>\n",
       "      <td>b'.#StormyDaniels, #MichaelWolfe, #JamesComey ...</td>\n",
       "      <td>StormyDaniels MichaelWolfe JamesComey</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592800</th>\n",
       "      <td>33</td>\n",
       "      <td>b'@NRDems The American people deserve the trut...</td>\n",
       "      <td>CultureOfCorruption</td>\n",
       "      <td>14</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592801</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Only 2 weeks left to submit your #app to the...</td>\n",
       "      <td>app copolitics CAC16 HouseOfCode co06</td>\n",
       "      <td>3</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592802</th>\n",
       "      <td>155</td>\n",
       "      <td>b'The #MuslimBan remains as un-American and of...</td>\n",
       "      <td>MuslimBan</td>\n",
       "      <td>48</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592803 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        favorite_count                                          full_text  \\\n",
       "0                    0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1                  258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2                    0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3                    9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4                    3  b'Pleased to support @amergateways at their Ju...   \n",
       "...                ...                                                ...   \n",
       "592798               3  b'This time, it focused on careers in #publics...   \n",
       "592799               5  b'.#StormyDaniels, #MichaelWolfe, #JamesComey ...   \n",
       "592800              33  b'@NRDems The American people deserve the trut...   \n",
       "592801               4  b'Only 2 weeks left to submit your #app to the...   \n",
       "592802             155  b'The #MuslimBan remains as un-American and of...   \n",
       "\n",
       "                                     hashtags  retweet_count    year party_id  \n",
       "0                                        KUSI             10  2017.0        R  \n",
       "1                                 Coronavirus            111  2020.0        R  \n",
       "2                                        MO03              2  2014.0        R  \n",
       "3                        TeamUSA WorldJuniors              3  2017.0        R  \n",
       "4                      ImmigrantHeritageMonth              3  2019.0        D  \n",
       "...                                       ...            ...     ...      ...  \n",
       "592798             publicservice publicsafety              0  2017.0        R  \n",
       "592799  StormyDaniels MichaelWolfe JamesComey              1  2018.0        R  \n",
       "592800                    CultureOfCorruption             14  2020.0        D  \n",
       "592801  app copolitics CAC16 HouseOfCode co06              3  2016.0        R  \n",
       "592802                              MuslimBan             48  2020.0        D  \n",
       "\n",
       "[592803 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf8c3c",
   "metadata": {},
   "source": [
    "Then we try to extract the most useful information. I tried to pair down the information as much as possible to try to get easy training. This means I tried to convert everthing, as easily as possible, to numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44df25b",
   "metadata": {},
   "source": [
    "First I start by getting the integer length of all tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c708c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[\"full_text\"].str.slice(1)\n",
    "length = text.str.len()\n",
    "length = length.to_frame()\n",
    "length.columns = ['length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7bb9b",
   "metadata": {},
   "source": [
    "Then I try to get the mentions of other accounts and then count the number of occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee65b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = dataset[\"full_text\"].str.findall('@(\\w+)')\n",
    "mentions = mentions.apply(lambda list: len(list))\n",
    "mentions = mentions.to_frame()\n",
    "mentions.columns = [\"mentions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586fdcc",
   "metadata": {},
   "source": [
    "Seperates out retweet count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be96e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = dataset[\"retweet_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d1226",
   "metadata": {},
   "source": [
    "Extracts year and from string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f040bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = dataset[\"year\"].str.extract(r'(\\d{4})')\n",
    "years = years.astype(\"Int64\")\n",
    "years.columns = [\"year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb21251",
   "metadata": {},
   "source": [
    "Here we split hashtags into lists and then count the total number of hashtags. I use a numpy array to find the unique values and then count them hashtags into a dictionary. I then take a slice of the dictionary of the top 500 hashtags and use them for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "504917f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "hashtags = dataset[\"hashtags\"].str.split(' ')\n",
    "\n",
    "tags = []\n",
    "for taglist in hashtags:\n",
    "    for item in taglist:\n",
    "        tags.append(item.lower())\n",
    "\n",
    "tags = np.asarray(tags)\n",
    "uniqueTags = np.unique(uniqueTags)\n",
    "\n",
    "tagList = uniqueTags.tolist()\n",
    "tagDict = {}\n",
    "\n",
    "for tag in uniqueTags:\n",
    "    count = np.where(tags == tag)[0]\n",
    "    count = len(ii)\n",
    "    if count != 1:\n",
    "        tagDict[tag] = count\n",
    "        \n",
    "topTags = dict(itertools.islice(tagDict.items(), 500))\n",
    "\n",
    "hashtags = hashtags.apply(lambda list: len(list))\n",
    "hashtags = hashtags.to_frame()\n",
    "hashtags.columns = [\"hashtags\"]\n",
    "\n",
    "tagDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ebacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900a9c8d",
   "metadata": {},
   "source": [
    "Convert party affiliation to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f80ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_id = dataset[\"party_id\"]\n",
    "party_id = party_id.apply(lambda String: \"0\" if (String==\"D\") else \"1\")\n",
    "party_id = party_id.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3d9d7",
   "metadata": {},
   "source": [
    "Collate the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df88231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592803 entries, 0 to 592802\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   length         592803 non-null  Int64\n",
      " 1   mentions       592803 non-null  int64\n",
      " 2   retweet_count  592803 non-null  int64\n",
      " 3   year           592803 non-null  Int64\n",
      " 4   hashtags       592803 non-null  int64\n",
      " 5   party_id       592803 non-null  int32\n",
      "dtypes: Int64(2), int32(1), int64(3)\n",
      "memory usage: 26.0 MB\n"
     ]
    }
   ],
   "source": [
    "input = pd.concat([length, mentions, retweets, years, hashtags, party_id], axis=1)\n",
    "labels = party_id \n",
    "input = input.fillna(input.median())\n",
    "input.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755081b",
   "metadata": {},
   "source": [
    "## Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a546d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as l\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7224636",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18c070b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set size: 29640\n"
     ]
    }
   ],
   "source": [
    "p = 0.05\n",
    "n = int(len(input) * p)\n",
    "trainset = input.iloc[0:n]\n",
    "trainlabels = labels.iloc[0:n]\n",
    "\n",
    "testset = input.iloc[n:2*n]\n",
    "testlabels = labels.iloc[n:2*n]\n",
    "print(\"Set size: {}\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712a00a",
   "metadata": {},
   "source": [
    "Convert pandas dataframe to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b4a7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "trainset = tf.convert_to_tensor(trainset, dtype=tf.int64)\n",
    "normalizer.adapt(trainset)\n",
    "normalizer(trainset)\n",
    "\n",
    "testlabels = tf.cast(testlabels, tf.bool)\n",
    "\n",
    "testset = tf.convert_to_tensor(testset, dtype=tf.int64)\n",
    "testlabels = tf.cast(testlabels, tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e266f",
   "metadata": {},
   "source": [
    "## Network Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a02155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "relu = tf.nn.relu\n",
    "softmax = tf.nn.softmax\n",
    "model.add(normalizer)\n",
    "model.add(l.GaussianNoise(0.1))\n",
    "model.add(l.Dense(5, activation=relu, input_shape=(5,)))\n",
    "model.add(l.Dense(2, activation=relu))\n",
    "model.add(l.Dense(5, activation=relu))\n",
    "model.add(l.GaussianNoise(0.1))\n",
    "model.add(l.Dense(1, activation=softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72804216",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24901561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29640/29640 [==============================] - 140s 5ms/step - loss: 0.0587 - accuracy: 0.9636\n",
      "Epoch 2/5\n",
      "29640/29640 [==============================] - 125s 4ms/step - loss: 9.8946e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "29640/29640 [==============================] - 133s 4ms/step - loss: 6.4964e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "29640/29640 [==============================] - 145s 5ms/step - loss: 5.5609e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "29640/29640 [==============================] - 136s 5ms/step - loss: 2.4588e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc77c2dd50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainset, trainlabels, epochs=5, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for i in range(2000):\n",
    "    x = testset[i]\n",
    "    y = testlabels[i]\n",
    "    prediction = tf.math.argmax(model(x, training=False), axis=1, output_type=tf.int64)\n",
    "    accuracy(prediction, y)\n",
    "\n",
    "print((accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849930d",
   "metadata": {},
   "source": [
    "Results: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c8711",
   "metadata": {},
   "source": [
    "Comments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a9a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
